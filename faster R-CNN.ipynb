{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "train_root = os.path.join(data_path, \"stage_2_train_images\")\n",
    "\n",
    "df = pd.read_csv(os.path.join(data_path, \"stage_2_train_labels.csv\"))\n",
    "\n",
    "df_pneumonia = df[df[\"Target\"] == 1]\n",
    "\n",
    "# 바운딩 박스 좌표 리스트\n",
    "df_grouped = df_pneumonia.groupby(\"patientId\").agg({\n",
    "    \"x\": list,\n",
    "    \"y\": list,\n",
    "    \"width\": list,\n",
    "    \"height\": list\n",
    "}).reset_index()\n",
    "\n",
    "train_files, test_files = train_test_split(df_grouped[\"patientId\"].tolist(), test_size=0.2, random_state=55) # tolist() 리스트 변환\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = df_grouped[df_grouped[\"patientId\"].isin(train_files)] # isin() 일치하는지 확인\n",
    "val_df = df_grouped[df_grouped[\"patientId\"].isin(val_files)]\n",
    "test_df = df_grouped[df_grouped[\"patientId\"].isin(test_files)]\n",
    "\n",
    "print(f\"폐렴 Train 데이터 개수: {len(train_df)}\")\n",
    "print(f\"폐렴 Val 데이터 개수: {len(val_df)}\")\n",
    "print(f\"폐렴 Test 데이터 개수: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_image(dicom_path):\n",
    "    dicom_data = pydicom.dcmread(dicom_path)\n",
    "    image = dicom_data.pixel_array.astype(\"uint8\") # 8비트로 변환\n",
    "\n",
    "    image = Image.fromarray(image).convert(\"RGB\")\n",
    "\n",
    "    imagenet_transform = transforms.Compose([\n",
    "        transforms.Resize((600, 600)), # 논문 권장 사이즈\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    return imagenet_transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_bbox(bbox, orig_size=(1024, 1024), new_size=(600, 600)):\n",
    "    \"\"\"\n",
    "    Bounding Box를 원본 크기에서 리사이즈된 크기에 맞게 변환하며, 좌표를 x1, y1, x2, y2로 변환.\n",
    "    \"\"\"\n",
    "    x_scale = new_size[0] / orig_size[0]\n",
    "    y_scale = new_size[1] / orig_size[1]\n",
    "\n",
    "    x1 = bbox[0] * x_scale\n",
    "    y1 = bbox[1] * y_scale\n",
    "    x2 = (bbox[0] + bbox[2]) * x_scale  # width → x2 변환\n",
    "    y2 = (bbox[1] + bbox[3]) * y_scale  # height → y2 변환\n",
    "\n",
    "    # 좌표값이 음수가 되지 않도록 보정\n",
    "    x1 = max(0, x1)\n",
    "    y1 = max(0, y1)\n",
    "    x2 = max(x1 + 1, x2)  # x2가 x1보다 작아지는 것 방지\n",
    "    y2 = max(y1 + 1, y2)  # y2가 y1보다 작아지는 것 방지\n",
    "\n",
    "    return [x1, y1, x2, y2]  # Faster R-CNN 형식으로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PneumoniaDetectionDataset(Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        dicom_path = os.path.join(self.img_dir, f\"{row['patientId']}.dcm\")\n",
    "        image = load_dicom_image(dicom_path)\n",
    "\n",
    "        # Bounding Box 변환 및 필터링\n",
    "        boxes = torch.tensor([\n",
    "            adjust_bbox([row[\"x\"][i], row[\"y\"][i], row[\"width\"][i], row[\"height\"][i]]) \n",
    "            for i in range(len(row[\"x\"]))\n",
    "        ], dtype=torch.float32)\n",
    "\n",
    "        # 너비(height)와 높이가 0이 아닌 경우만 유지\n",
    "        valid_boxes = [box for box in boxes if (box[2] > box[0] and box[3] > box[1])]\n",
    "\n",
    "        # 유효한 Bounding Box가 없는 경우 샘플 삭제\n",
    "        if len(valid_boxes) == 0:\n",
    "            return self.__getitem__((idx + 1) % len(self))  # 다음 인덱스 샘플을 반환\n",
    "\n",
    "        valid_boxes = torch.stack(valid_boxes) if valid_boxes else torch.zeros((0, 4), dtype=torch.float32)\n",
    "        labels = torch.ones((len(valid_boxes),), dtype=torch.int64)\n",
    "\n",
    "        return image, {\"boxes\": valid_boxes, \"labels\": labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PneumoniaDetectionDataset(train_df, \"data/stage_2_train_images\")\n",
    "\n",
    "# 데이터셋 크기 확인\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# 첫 번째 데이터 샘플 로드\n",
    "image, target = dataset[0]\n",
    "\n",
    "# 이미지 텐서의 크기 확인\n",
    "print(f\"Image Shape: {image.shape}\")  # (C, H, W)\n",
    "\n",
    "# Bounding Box 정보 확인\n",
    "print(f\"Bounding Boxes Shape: {target['boxes'].shape}\")  # (num_boxes, 4)\n",
    "print(f\"Labels: {target['labels']}\")  # Class labels\n",
    "\n",
    "# Bounding Box 좌표 출력\n",
    "print(f\"Bounding Boxes:\\n{target['boxes'].numpy()}\")  # Tensor → NumPy 변환 후 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PneumoniaDetectionDataset(train_df, train_root)\n",
    "val_dataset = PneumoniaDetectionDataset(val_df, train_root)\n",
    "test_dataset = PneumoniaDetectionDataset(test_df, train_root)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, targets = zip(*batch)  # 이미지와 타겟을 분리\n",
    "    return list(images), list(targets)  # 리스트 형태로 변환하여 반환\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(f\"Train 데이터 개수: {len(train_dataset)}\")\n",
    "print(f\"Validation 데이터 개수: {len(val_dataset)}\")\n",
    "print(f\"Test  데이터 개수: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 체크\n",
    "\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "\n",
    "sample_image, sample_label = train_dataset[0]\n",
    "\n",
    "print(f\"Image Shape: {sample_image.shape}\")\n",
    "print(f\"Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 체크\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "batch_images, batch_labels = batch\n",
    "\n",
    "print(f\"Batch Image Shape: {batch_images[0].shape}\")\n",
    "print(f\"Batch Labels: {batch_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "num_classes = 2  # 배경과 폐렴 클래스를 구분\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features # cls_score.in_features는 FC Layer의 입력 뉴런 개수\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim as optim\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "# num_epochs = 100\n",
    "# best_val_loss = float('inf')\n",
    "# early_stopping_patience = 10\n",
    "# early_stopping_counter = 0\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"\\nEpoch [{epoch+1}/{num_epochs}] 시작\\n\")\n",
    "\n",
    "#     # Train Step\n",
    "#     model.train()\n",
    "#     total_train_loss = 0\n",
    "#     total_train_correct = 0\n",
    "#     total_train_samples = 0\n",
    "\n",
    "#     train_loader_tqdm = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "#     for images, targets in train_loader_tqdm:\n",
    "#         images = [img.to(device) for img in images]\n",
    "#         targets = [{k: v.to(device) for k, v in target.items()} for target in targets] \n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss_dict = model(images, targets) \n",
    "        \n",
    "#         # loss = sum(loss_dict.values())  # dict 형식이므로 `.values()` 사용 가능\n",
    "#         # loss = sum(loss for loss in loss_dict.values())\n",
    "#         loss = loss_dict['loss_classifier'] + 10*loss_dict['loss_box_reg'] + loss_dict['loss_objectness'] + 10*loss_dict['loss_rpn_box_reg']\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_train_loss += loss.item()\n",
    "\n",
    "#         train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "#         # Accuracy 계산 (폐렴이 포함된 이미지 비율)\n",
    "#         for target in targets:\n",
    "#             total_train_samples += len(target[\"labels\"])\n",
    "#             total_train_correct += target[\"labels\"].sum().item()  # 모든 박스가 폐렴(1)이므로 단순 합\n",
    "\n",
    "#     avg_train_loss = total_train_loss / len(train_loader)\n",
    "#     train_accuracy = 100 * (total_train_correct / total_train_samples)\n",
    "\n",
    "#     # Validation Step\n",
    "#     model.eval()\n",
    "#     total_val_loss = 0\n",
    "#     total_val_correct = 0\n",
    "#     total_val_samples = 0\n",
    "\n",
    "#     val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "#     with torch.no_grad():\n",
    "#         for images, targets in val_loader_tqdm:\n",
    "#             images = [img.to(device) for img in images]\n",
    "#             targets = [{k: v.to(device) for k, v in target.items()} for target in targets]\n",
    "\n",
    "#             loss_dict = model(images, targets)  # 올바른 입력\n",
    "#             #loss = sum(loss_dict.values())\n",
    "#             print(\"test: \", loss_dict)\n",
    "#             # loss = sum(loss for loss in loss_dict.values())\n",
    "#             loss = loss_dict['loss_classifier'] + 10*loss_dict['loss_box_reg'] + loss_dict['loss_objectness'] + 10*loss_dict['loss_rpn_box_reg']\n",
    "\n",
    "\n",
    "#             total_val_loss += loss.item()\n",
    "#             val_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "#             # Accuracy 계산\n",
    "#             for target in targets:\n",
    "#                 total_val_samples += len(target[\"labels\"])\n",
    "#                 total_val_correct += target[\"labels\"].sum().item()\n",
    "\n",
    "#     avg_val_loss = total_val_loss / len(val_loader)\n",
    "#     val_accuracy = 100 * (total_val_correct / total_val_samples)\n",
    "\n",
    "#     # Learning Rate Scheduler 업데이트\n",
    "#     scheduler.step(avg_val_loss)\n",
    "\n",
    "#     # Checkpoint 저장\n",
    "#     if avg_val_loss < best_val_loss:\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         early_stopping_counter = 0\n",
    "#         torch.save(model.state_dict(), \"FasterRCNN_best.pth\")\n",
    "#         print(f\"Best Model Saved! Epoch [{epoch+1}] | Val Loss: {avg_val_loss:.4f}\")\n",
    "#     else:\n",
    "#         early_stopping_counter += 1\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "#           f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | \"\n",
    "#           f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\\n\")\n",
    "#     print(\"---------------------------------------------------------------\")\n",
    "\n",
    "#     # Early Stopping 확인\n",
    "#     if early_stopping_counter >= early_stopping_patience:\n",
    "#         print(f\"Early Stopping at Epoch {epoch+1} | Best Val Loss: {best_val_loss:.4f}\")\n",
    "#         break  # 학습 중단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yunseo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "# 옵티마이저 및 스케줄러 설정\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "\n",
    "num_epochs = 100\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "early_stopping_patience = 10  \n",
    "early_stopping_counter = 0  \n",
    "best_iou = 0  \n",
    "\n",
    "train_losses = []  # Train Loss 저장 리스트\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}] 시작\\n\")\n",
    "\n",
    "    # Training Step\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for images, targets in train_loader_tqdm:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in target.items()} for target in targets] \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)  \n",
    "        loss = loss_dict['loss_classifier'] + 10 * loss_dict['loss_box_reg'] + \\\n",
    "               loss_dict['loss_objectness'] + 10 * loss_dict['loss_rpn_box_reg']\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)  # Train Loss 저장\n",
    "\n",
    "    # Validation Step\n",
    "    model.eval()\n",
    "    total_iou = 0\n",
    "    total_detections = 0\n",
    "\n",
    "    val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "    with torch.no_grad():\n",
    "        for images, targets in val_loader_tqdm:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in target.items()} for target in targets]\n",
    "\n",
    "            predictions = model(images)  \n",
    "\n",
    "            for pred, target in zip(predictions, targets):\n",
    "                pred_boxes = pred[\"boxes\"]  \n",
    "                gt_boxes = target[\"boxes\"]  \n",
    "\n",
    "                if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "                    ious = box_iou(pred_boxes, gt_boxes)  \n",
    "                    max_iou_per_pred, _ = ious.max(dim=1)  \n",
    "                    total_iou += max_iou_per_pred.sum().item()  \n",
    "                    total_detections += len(pred_boxes)\n",
    "\n",
    "    avg_iou = total_iou / total_detections if total_detections > 0 else 0\n",
    "\n",
    "    # 체크포인트 저장 (최고 IoU 갱신 시)\n",
    "    if avg_iou > best_iou:\n",
    "        best_iou = avg_iou  \n",
    "        early_stopping_counter = 0  # Early Stopping 리셋\n",
    "        torch.save(model.state_dict(), \"FasterRCNN_best_cossine.pth\")  \n",
    "        print(f\"Best Model Saved! Epoch [{epoch+1}] | Best IoU: {best_iou:.4f}\")\n",
    "\n",
    "    else:\n",
    "        early_stopping_counter += 1  # 개선되지 않으면 카운터 증가\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "          f\"Avg IoU: {avg_iou:.4f}\\n\")\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "\n",
    "    # Early Stopping 확인 (10번 연속 IoU 상승 실패 시 스탑)\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(f\"Early Stopping at Epoch {epoch+1} | Best IoU: {best_iou:.4f}\")\n",
    "        break  # 학습 중단\n",
    "\n",
    "# Train Loss 그래프 출력\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', linestyle='-')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Loss\")\n",
    "plt.title(\"Training Loss Over Epochs\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    total_iou = 0\n",
    "    total_detections = 0\n",
    "    all_ious = []\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            print(images[0].shape)\n",
    "            targets = [{k: v.to(device) for k, v in target.items()} for target in targets]\n",
    "            \n",
    "            predictions = model(images)  # 모델 예측\n",
    "            print(predictions)\n",
    "            for img, pred, target in zip(images, predictions, targets):\n",
    "                pred_boxes = pred[\"boxes\"].detach().cpu().numpy()\n",
    "                gt_boxes = target[\"boxes\"].detach().cpu().numpy()\n",
    "                \n",
    "                if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "                    ious = box_iou(torch.tensor(pred_boxes), torch.tensor(gt_boxes))\n",
    "                    max_iou_per_pred, _ = ious.max(dim=1)\n",
    "                    total_iou += max_iou_per_pred.sum().item()\n",
    "                    total_detections += len(pred_boxes)\n",
    "                    all_ious.extend(max_iou_per_pred.tolist())\n",
    "                \n",
    "                # # Precision, Recall 계산\n",
    "                # tp = sum(max_iou_per_pred > 0.5)\n",
    "                # fp = len(pred_boxes) - tp\n",
    "                # fn = len(gt_boxes) - tp\n",
    "                \n",
    "                # precision = tp / (tp + fp + 1e-6)  # Precision 계산\n",
    "                # recall = tp / (tp + fn + 1e-6)  # Recall 계산\n",
    "                \n",
    "                # all_precisions.append(precision)\n",
    "                # all_recalls.append(recall)\n",
    "                \n",
    "                # Ground-Truth와 예측 박스 시각화 (Grayscale)\n",
    "                visualize_boxes(img.cpu(), pred_boxes, gt_boxes)\n",
    "\n",
    "    avg_iou = total_iou / total_detections if total_detections > 0 else 0\n",
    "    mean_ap = np.mean(all_ious) if all_ious else 0\n",
    "    mean_precision = np.mean(all_precisions) if all_precisions else 0\n",
    "    mean_recall = np.mean(all_recalls) if all_recalls else 0\n",
    "    \n",
    "    print(f\"Test IoU: {avg_iou:.4f}\")\n",
    "    print(f\"Mean Average Precision (mAP): {mean_ap:.4f}\")\n",
    "    print(f\"Mean Precision: {mean_precision:.4f}, Mean Recall: {mean_recall:.4f}\")\n",
    "\n",
    "def visualize_boxes(image, pred_boxes, gt_boxes):\n",
    "    image = image.squeeze(0).numpy()  # Grayscale 변환\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "    for box in gt_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='green', linewidth=2, label='GT'))\n",
    "    \n",
    "    for box in pred_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, edgecolor='red', linewidth=2, label='Pred'))\n",
    "    \n",
    "    plt.legend([\"Ground-Truth\", \"Prediction\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    total_iou = 0\n",
    "    total_detections = 0\n",
    "    all_ious = []\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            print(\"Image shape:\", images[0].shape)\n",
    "            targets = [{k: v.to(device) for k, v in target.items()} for target in targets]\n",
    "            \n",
    "            predictions = model(images)  # 모델 예측\n",
    "            print(\"Predictions:\", predictions)\n",
    "            for img, pred, target in zip(images, predictions, targets):\n",
    "                pred_boxes = pred[\"boxes\"].detach().cpu().numpy()\n",
    "                gt_boxes = target[\"boxes\"].detach().cpu().numpy()\n",
    "                \n",
    "                if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "                    ious = box_iou(torch.tensor(pred_boxes), torch.tensor(gt_boxes))\n",
    "                    max_iou_per_pred, _ = ious.max(dim=1)\n",
    "                    total_iou += max_iou_per_pred.sum().item()\n",
    "                    total_detections += len(pred_boxes)\n",
    "                    all_ious.extend(max_iou_per_pred.tolist())\n",
    "                \n",
    "                # Precision, Recall 계산 (필요하면 주석 해제 후 조건 처리 추가)\n",
    "                # if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "                #     tp = sum(max_iou_per_pred > 0.5)\n",
    "                # else:\n",
    "                #     tp = 0\n",
    "                # fp = len(pred_boxes) - tp\n",
    "                # fn = len(gt_boxes) - tp\n",
    "                # precision = tp / (tp + fp + 1e-6) if (tp + fp) > 0 else 0.0\n",
    "                # recall = tp / (tp + fn + 1e-6) if (tp + fn) > 0 else 0.0\n",
    "                # all_precisions.append(precision)\n",
    "                # all_recalls.append(recall)\n",
    "                \n",
    "                # Ground-Truth와 예측 박스 시각화 (그레이스케일)\n",
    "                visualize_boxes(img.cpu(), pred_boxes, gt_boxes)\n",
    "\n",
    "    avg_iou = total_iou / total_detections if total_detections > 0 else 0\n",
    "    mean_ap = np.mean(all_ious) if all_ious else 0\n",
    "    mean_precision = np.mean(all_precisions) if all_precisions else 0\n",
    "    mean_recall = np.mean(all_recalls) if all_recalls else 0\n",
    "    \n",
    "    print(f\"Test IoU: {avg_iou:.4f}\")\n",
    "    print(f\"Mean Average Precision (mAP): {mean_ap:.4f}\")\n",
    "    print(f\"Mean Precision: {mean_precision:.4f}, Mean Recall: {mean_recall:.4f}\")\n",
    "\n",
    "def visualize_boxes(image, pred_boxes, gt_boxes):\n",
    "    # 이미지가 3채널인 경우, (H,W,C)로 변환 후 그레이스케일로 변환\n",
    "    image = image.permute(1, 2, 0).numpy()  # (H, W, C)\n",
    "    image_gray = np.mean(image, axis=2)  # 그레이스케일 (평균내기)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image_gray, cmap='gray')\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    # 한 번만 label을 설정하기 위한 플래그\n",
    "    gt_label_added = False\n",
    "    pred_label_added = False\n",
    "    \n",
    "    for box in gt_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        if not gt_label_added:\n",
    "            ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                         fill=False, edgecolor='green', linewidth=2, label='GT'))\n",
    "            gt_label_added = True\n",
    "        else:\n",
    "            ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                         fill=False, edgecolor='green', linewidth=2))\n",
    "    \n",
    "    for box in pred_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        if not pred_label_added:\n",
    "            ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                         fill=False, edgecolor='red', linewidth=2, label='Pred'))\n",
    "            pred_label_added = True\n",
    "        else:\n",
    "            ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1,\n",
    "                         fill=False, edgecolor='red', linewidth=2))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import fasterrcnn_resnet50_fpn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.ops import box_iou\n",
    "\n",
    "# 모델 로드 함수\n",
    "def load_model(checkpoint_path, device):\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=False, num_classes=2)  # 클래스 수 조정\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# 모델 체크포인트 경로\n",
    "checkpoint_path = \"FasterRCNN_best_cossine.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 로드\n",
    "model = load_model(checkpoint_path, device)\n",
    "\n",
    "# 테스트 데이터셋 로드 (이 부분은 사용자 데이터셋에 맞게 조정 필요)\n",
    "# 예시로 DataLoader만 생성 (실제 데이터셋을 사용해야 함)\n",
    "# test_loader = DataLoader(your_test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 모델 평가 함수 실행\n",
    "test_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision.ops import box_iou\n",
    "import torchvision\n",
    "\n",
    "# 모델 로드\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, 2)  # 배경 + 폐렴\n",
    "model.load_state_dict(torch.load(\"FasterRCNN_best.pth\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# IoU Threshold 설정\n",
    "IOU_THRESHOLD = 0.5\n",
    "\n",
    "# 평가 변수 초기화\n",
    "total_loss = 0\n",
    "total_loss_classifier = 0\n",
    "total_loss_box_reg = 0\n",
    "total_loss_objectness = 0\n",
    "total_loss_rpn_box_reg = 0\n",
    "total_iou = 0\n",
    "total_detections = 0\n",
    "\n",
    "test_loader_tqdm = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "\n",
    "# Test Loop 시작\n",
    "with torch.no_grad():\n",
    "    for images, targets in test_loader_tqdm:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in target.items()} for target in targets]\n",
    "\n",
    "        # 손실 계산\n",
    "        model.train()  # Training Mode로 변경 (손실 계산을 위해)\n",
    "        loss_dict = model(images, targets)  # 손실 반환\n",
    "        model.eval()  # 다시 평가 모드로 변경\n",
    "\n",
    "        # 손실 값 개별 저장\n",
    "        loss_classifier = loss_dict[\"loss_classifier\"].item()\n",
    "        loss_box_reg = loss_dict[\"loss_box_reg\"].item()\n",
    "        loss_objectness = loss_dict[\"loss_objectness\"].item()\n",
    "        loss_rpn_box_reg = loss_dict[\"loss_rpn_box_reg\"].item()\n",
    "\n",
    "        # 총 손실 계산\n",
    "        total_sample_loss = loss_classifier + loss_box_reg + loss_objectness + loss_rpn_box_reg\n",
    "\n",
    "        # IoU 계산\n",
    "        predictions = model(images)\n",
    "        for pred, target in zip(predictions, targets):\n",
    "            pred_boxes = pred[\"boxes\"].cpu().numpy()\n",
    "            gt_boxes = target[\"boxes\"].cpu().numpy()\n",
    "\n",
    "            if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
    "                ious = box_iou(torch.tensor(pred_boxes), torch.tensor(gt_boxes))\n",
    "                max_iou_per_pred, _ = ious.max(dim=1)\n",
    "\n",
    "                total_iou += max_iou_per_pred.sum().item()\n",
    "                total_detections += len(pred_boxes)\n",
    "\n",
    "        # 손실값 저장\n",
    "        total_loss += total_sample_loss\n",
    "        total_loss_classifier += loss_classifier\n",
    "        total_loss_box_reg += loss_box_reg\n",
    "        total_loss_objectness += loss_objectness\n",
    "        total_loss_rpn_box_reg += loss_rpn_box_reg\n",
    "\n",
    "        # 손실값 및 IoU 출력\n",
    "        print(f\"Loss Breakdown - Classifier: {loss_classifier:.4f}, Box Reg: {loss_box_reg:.4f}, \"\n",
    "              f\"Objectness: {loss_objectness:.4f}, RPN Box Reg: {loss_rpn_box_reg:.4f}, \"\n",
    "              f\"Total Loss: {total_sample_loss:.4f}\")\n",
    "\n",
    "# 테스트 결과 출력\n",
    "avg_loss = total_loss / len(test_loader)\n",
    "avg_loss_classifier = total_loss_classifier / len(test_loader)\n",
    "avg_loss_box_reg = total_loss_box_reg / len(test_loader)\n",
    "avg_loss_objectness = total_loss_objectness / len(test_loader)\n",
    "avg_loss_rpn_box_reg = total_loss_rpn_box_reg / len(test_loader)\n",
    "avg_iou = total_iou / total_detections if total_detections > 0 else 0\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"Average Total Loss: {avg_loss:.4f}\")\n",
    "print(f\"Average Classifier Loss: {avg_loss_classifier:.4f}\")\n",
    "print(f\"Average Box Regression Loss: {avg_loss_box_reg:.4f}\")\n",
    "print(f\"Average Objectness Loss: {avg_loss_objectness:.4f}\")\n",
    "print(f\"Average RPN Box Regression Loss: {avg_loss_rpn_box_reg:.4f}\")\n",
    "print(f\"Test IoU: {avg_iou:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
