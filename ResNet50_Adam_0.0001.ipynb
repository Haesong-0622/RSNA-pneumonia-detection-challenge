{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader # 없어도 되지만 빠르게 데이터를 불러오기 위해서 필요함\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "train_path = 'data/'\n",
    "train_root = os.path.join(train_path, \"stage_2_train_images\")  # train 이미지 경로\n",
    "\n",
    "train_img_ids = os.listdir(train_root)\n",
    "\n",
    "train_files, test_files = train_test_split(train_img_ids, test_size=0.2, random_state=55) # random_state 난수 생성 fix\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"총 이미지 개수: {len(train_img_ids)}\")\n",
    "print(f\"Train 데이터 개수: {len(train_files)}\")\n",
    "print(f\"Validation 데이터 개수: {len(val_files)}\")\n",
    "print(f\"Test 데이터 개수: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image=label 매칭\n",
    "\n",
    "df = pd.read_csv(\"data/stage_2_train_labels.csv\")\n",
    "df_grouped = df.groupby(\"patientId\").agg({\"Target\": \"first\"}).reset_index() # 새로운 데이터 프레임 변환\n",
    "\n",
    "train_df = df_grouped[df_grouped[\"patientId\"].isin([f.split(\".\")[0] for f in train_files])]\n",
    "val_df = df_grouped[df_grouped[\"patientId\"].isin([f.split(\".\")[0] for f in val_files])]\n",
    "test_df = df_grouped[df_grouped[\"patientId\"].isin([f.split(\".\")[0] for f in test_files])]\n",
    "\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image.convert('RGB') 적용\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "imagenet_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # imageNet 모델 입력 크기기\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # RGB 채널의 평균과 표준편차차\n",
    "])\n",
    "\n",
    "def load_dicom_image(dicom_path):\n",
    "    dicom_data = pydicom.dcmread(dicom_path)\n",
    "    image = dicom_data.pixel_array.astype(\"uint8\")\n",
    "\n",
    "    image = Image.fromarray(image).convert(\"RGB\")\n",
    "\n",
    "    image = imagenet_transform(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 생성 및 dataloader 준비\n",
    "\n",
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        dicom_path = os.path.join(self.img_dir, f\"{row['patientId']}.dcm\")\n",
    "\n",
    "        image = load_dicom_image(dicom_path)\n",
    "        label = torch.tensor(row[\"Target\"], dtype=torch.long)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 준비\n",
    "\n",
    "train_dataset = PneumoniaDataset(train_df, train_root)\n",
    "val_dataset = PneumoniaDataset(val_df, train_root)\n",
    "test_dataset = PneumoniaDataset(test_df, train_root)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader =  DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Train 데이터 개수: {len(train_dataset)}\")\n",
    "print(f\"Validation 데이터 개수: {len(val_dataset)}\")\n",
    "print(f\"Test  데이터 개수: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 체크\n",
    "\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "\n",
    "sample_image, sample_label = train_dataset[0]\n",
    "\n",
    "print(f\"Image Shape: {sample_image.shape}\")\n",
    "print(f\"Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 체크\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "batch_images, batch_labels = batch\n",
    "\n",
    "print(f\"Batch Image Shape: {batch_images.shape}\")\n",
    "print(f\"Batch Labels: {batch_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# CLAHE 적용하는 함수\n",
    "def apply_CLAHE(image_array):\n",
    "    \"\"\"CLAHE(Contrast Limited Adaptive Histogram Equalization)를 적용하는 함수\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))  # CLAHE 생성\n",
    "    image_clahe = clahe.apply(image_array)  # CLAHE 적용\n",
    "    return image_clahe\n",
    "\n",
    "def load_dicom_image(dicom_path):\n",
    "    \"\"\"DICOM 파일을 불러와 CLAHE를 적용한 후, PyTorch 텐서로 변환\"\"\"\n",
    "    dicom_data = pydicom.dcmread(dicom_path)\n",
    "    image = dicom_data.pixel_array\n",
    "\n",
    "    # 데이터 타입 확인 후 변환 (uint8 필요)\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (image / np.max(image) * 255).astype(np.uint8)\n",
    "\n",
    "    # CLAHE 적용\n",
    "    image = apply_CLAHE(image)\n",
    "\n",
    "    # PIL Image 변환 및 RGB 변환\n",
    "    image = Image.fromarray(image).convert(\"RGB\")\n",
    "\n",
    "    # torchvision transforms 적용\n",
    "    imagenet_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # 모델에 맞는 크기로 조정\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet Mean, Std 적용\n",
    "    ])\n",
    "    \n",
    "    image = imagenet_transform(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Dataset 클래스에서 CLAHE 적용 추가\n",
    "class PneumoniaDataset(Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        dicom_path = os.path.join(self.img_dir, f\"{row['patientId']}.dcm\")\n",
    "\n",
    "        # 수정: CLAHE가 적용된 DICOM 이미지 로드\n",
    "        image = load_dicom_image(dicom_path)\n",
    "        label = torch.tensor(row[\"Target\"], dtype=torch.long)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# DataLoader 준비\n",
    "batch_size = 64\n",
    "train_dataset = PneumoniaDataset(train_df, train_root)\n",
    "val_dataset = PneumoniaDataset(val_df, train_root)\n",
    "test_dataset = PneumoniaDataset(test_df, train_root)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 데이터셋 확인 (CLAHE 적용 후)\n",
    "sample_image, sample_label = train_dataset[0]\n",
    "\n",
    "print(f\"Image Shape: {sample_image.shape}\")\n",
    "print(f\"Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# 샘플 이미지 선택\n",
    "sample_dicom_path = os.path.join(train_root, f\"{train_df.iloc[0]['patientId']}.dcm\")\n",
    "\n",
    "# CLAHE 적용 전 이미지 로드 함수\n",
    "def load_dicom_image_without_clahe(dicom_path):\n",
    "    dicom_data = pydicom.dcmread(dicom_path)\n",
    "    image = dicom_data.pixel_array\n",
    "    \n",
    "    # 데이터 타입 확인 후 변환 (uint8 필요)\n",
    "    if image.dtype != np.uint8:\n",
    "        image = (image / np.max(image) * 255).astype(np.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# CLAHE 적용 후 이미지 로드\n",
    "image_without_clahe = load_dicom_image_without_clahe(sample_dicom_path)\n",
    "image_with_clahe = apply_CLAHE(image_without_clahe)\n",
    "\n",
    "# 이미지 시각화\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(image_without_clahe, cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(image_with_clahe, cmap='gray')\n",
    "ax[1].set_title('CLAHE Applied')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선정\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# import timm\n",
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "# model = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "# num_features = model.classifier.in_features\n",
    "# model.classifier = nn.Linear(num_features, 1)\n",
    "model.fc = nn.Linear(num_features, 1)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss() # loss\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001) \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "\n",
    "# 학습 파라미터\n",
    "num_epochs = 100  \n",
    "best_val_loss = float('inf')  # 가장 낮은 Validation Loss 저장\n",
    "early_stopping_patience = 10   # Early Stopping 기준 (연속 10 Epoch 동안 개선되지 않으면 학습 중단)\n",
    "early_stopping_counter = 0    # Early Stopping 카운터\n",
    "\n",
    "# Learning Rate Scheduler \n",
    "# factor = 0.1 (학습률 10배 감소)\n",
    "# patience = 10 (10번 안에 loss가 감소하지 않으면)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}] start\\n\")  # Epoch 시작 \n",
    "\n",
    "    # Train \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f\"Training\", leave=False)\n",
    "\n",
    "    for images, labels in train_loader_tqdm:\n",
    "        images, labels = images.to(device), labels.to(device).unsqueeze(1).float() # GPU로 데이터 이동, labels 차원 추가 (Binary Classification)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        predicted = (outputs > 0.5).float()  # Binary Classification 예측\n",
    "\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())  # 실시간 손실 표시\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train  \n",
    "\n",
    "    # Validation 단계\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    val_loader_tqdm = tqdm(val_loader, desc=f\"Validation\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader_tqdm:\n",
    "            images, labels = images.to(device), labels.to(device).unsqueeze(1).float()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            predicted = (outputs > 0.5).float()\n",
    "\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            val_loader_tqdm.set_postfix(loss=loss.item())  # 실시간 손실 표시\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val \n",
    "\n",
    "    # Learning Rate Scheduler 업데이트 (Validation Loss 기반)\n",
    "    # scheduler.step()\n",
    "    scheduler.step(val_loss)  \n",
    "\n",
    "    # Checkpoint 저장 (Validation Loss가 개선될 경우만 저장)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss  # 최소 손실 갱신\n",
    "        early_stopping_counter = 0  # Early Stopping 카운터 초기화\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': best_val_loss,\n",
    "            'val_accuracy': val_accuracy\n",
    "        }\n",
    "        torch.save(checkpoint, \"ResNet50_Adam_0.0001.pth\")\n",
    "        print(f\"Best Model Saved! Epoch [{epoch+1}] | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    else:\n",
    "        early_stopping_counter += 1  # 개선되지 않으면 카운트 증가\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\\n\")\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "\n",
    "    # Early Stopping 확인\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(f\"Early Stopping at Epoch {epoch+1} | Best Val Loss: {best_val_loss:.4f}\")\n",
    "        break  # 학습 중단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import torchvision.models as models  # torchvision 사용\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ResNet101 모델 생성 (학습할 때 사용한 것과 동일하게 설정해야 함)\n",
    "model = models.resnet50(pretrained=False)  # 사전 학습된 모델 사용 X (학습된 가중치 로드할 것이므로)\n",
    "\n",
    "# 모델의 마지막 레이어 수정 (학습 때와 동일해야 함)\n",
    "num_features = model.fc.in_features  # ResNet101의 FC Layer 입력 크기 가져오기\n",
    "model.fc = nn.Linear(num_features, 1)  # 이진 분류(Binary Classification)용 Fully Connected Layer 수정\n",
    "\n",
    "# 모델 가중치 로드\n",
    "checkpoint = torch.load(\"ResNet50_Adam_0.0001.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()  # 모델을 평가 모드로 변경\n",
    "\n",
    "# 손실 함수 정의\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 테스트 실행\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "# 예측값 저장 리스트\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "all_probabilities = []\n",
    "\n",
    "test_loader_tqdm = tqdm(test_loader, desc=f\"Testing\", leave=False)\n",
    "\n",
    "with torch.no_grad():  # 역전파 불필요\n",
    "    for images, labels in test_loader_tqdm:\n",
    "        images, labels = images.to(device), labels.to(device).unsqueeze(1).float()\n",
    "\n",
    "        # 모델 예측\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        probabilities = torch.sigmoid(outputs)  # 로짓(logit)을 확률로 변환\n",
    "        predicted = (probabilities > 0.5).float()  # Binary Classification (0.5 기준)\n",
    "\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "\n",
    "        test_loader_tqdm.set_postfix(loss=loss.item())  # 실시간 손실 표시\n",
    "\n",
    "        # 예측값 저장\n",
    "        all_labels.extend(labels.cpu().numpy())  # 실제값\n",
    "        all_predictions.extend(predicted.cpu().numpy())  # 예측값\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())  # 확률값\n",
    "\n",
    "# 최종 결과 계산\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * correct_test / total_test\n",
    "\n",
    "# Confusion Matrix 계산\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "# Sensitivity / Specificity 계산\n",
    "sensitivity = TP / (TP + FN)  \n",
    "specificity = TN / (TN + FP)  \n",
    "\n",
    "# ROC Curve 계산\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probabilities)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# 최종 결과 출력\n",
    "print(f\"\\nTest Results - Loss: {test_loss:.4f}, Accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Confusion Matrix 시각화\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Negative\", \"Positive\"], yticklabels=[\"Negative\", \"Positive\"])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve 시각화\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0,1], [0,1], color='gray', linestyle='--')  # 대각선 기준선\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
